{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7676ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91a8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PER_CLASS = 1200000000000\n",
    "\n",
    "def process_csv_file(path, counts):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['user_primary_language'] == 'en']\n",
    "    df = df[~df['text'].astype(str).str.contains(r'\\{\\{.*?\\}\\}', regex=True)]\n",
    "\n",
    "    x = df[[\n",
    "        \"text\", \"user_primary_language\", \"Bullying\", \"Fighting\", \"Sexting\", \"Vulgar\", \"Drugs\",\n",
    "        \"InGame\", \"Alarm\", \"Fraud\", \"Racist\", \"Religion\", \"Junk\", \"Website\", \"Grooming\",\n",
    "        \"PublicThreats\", \"RealName\", \"ExtremistRecruitment\", \"Subversive\", \"Sentiment\", \"Politics\"\n",
    "    ]].fillna(0)\n",
    "\n",
    "    label_cols = x.columns.difference(['text', 'user_primary_language'])\n",
    "\n",
    "    rows = []\n",
    "    for _, row in x.iterrows():\n",
    "        if all(counts[d] >= MAX_PER_CLASS for d in ['accepted', 'pending', 'blocked']):\n",
    "            break\n",
    "\n",
    "        text = row['text']\n",
    "        all_zero = (row[label_cols] == 0).all()\n",
    "\n",
    "        if all_zero:\n",
    "            if counts['accepted'] < MAX_PER_CLASS:\n",
    "                counts['accepted'] += 1\n",
    "                rows.append({\n",
    "                    'Text': text,\n",
    "                    'Label': 'Nothing Wrong',\n",
    "                    'Status': 0,\n",
    "                    'Decision': 'accepted'\n",
    "                })\n",
    "        else:\n",
    "            for label in label_cols:\n",
    "                status = int(row[label])\n",
    "                if status == 0:\n",
    "                    continue\n",
    "\n",
    "                if status in [0, 1, 2]:\n",
    "                    decision = 'accepted'\n",
    "                elif status in [3, 4]:\n",
    "                    decision = 'pending'\n",
    "                elif status in [5,6, 7]:\n",
    "                    decision = 'blocked'\n",
    "                else:\n",
    "                    decision = 'unknown'\n",
    "\n",
    "                if counts.get(decision, 0) >= MAX_PER_CLASS:\n",
    "                    continue\n",
    "\n",
    "                counts[decision] += 1\n",
    "                rows.append({\n",
    "                    'Text': text,\n",
    "                    'Label': label,\n",
    "                    'Status': status,\n",
    "                    'Decision': decision\n",
    "                })\n",
    "    return rows, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2acedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(df):\n",
    "    summary_data = []\n",
    "\n",
    "    # Overall decision summary\n",
    "    decision_counts = df['Decision'].value_counts().to_dict()\n",
    "    summary_data.append(['Summary'])\n",
    "    summary_data.append(['Overall accepted', decision_counts.get('accepted', 0)])\n",
    "    summary_data.append(['Overall pending', decision_counts.get('pending', 0)])\n",
    "    summary_data.append(['Overall blocked', decision_counts.get('blocked', 0)])\n",
    "    summary_data.append([])\n",
    "\n",
    "    # \"Nothing Wrong\"\n",
    "    nothing_wrong_count = df[df['Label'] == 'Nothing Wrong'].shape[0]\n",
    "    summary_data.append(['Nothing Wrong', nothing_wrong_count])\n",
    "    summary_data.append([])\n",
    "\n",
    "    # Per-label summary\n",
    "    summary_data.append(['Per-label Summary', 'Accepted', 'Pending', 'Blocked'])\n",
    "    label_stats = df[df['Label'] != 'Nothing Wrong'].groupby(['Label', 'Decision']).size().unstack(fill_value=0)\n",
    "\n",
    "    for label in label_stats.index:\n",
    "        accepted = label_stats.loc[label].get('accepted', 0)\n",
    "        pending = label_stats.loc[label].get('pending', 0)\n",
    "        blocked = label_stats.loc[label].get('blocked', 0)\n",
    "        summary_data.append([label, accepted, pending, blocked])\n",
    "\n",
    "    # Save summary\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    #summary_df.to_csv(\"summary_report_csv.csv\", index=False, header=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # Print\n",
    "    print(\"\\nðŸ“Š Summary Report:\\n\")\n",
    "    for row in summary_data:\n",
    "        print(', '.join(str(cell) for cell in row if cell != ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceef1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_clean_summary_for_folder(folder_path):\n",
    "    combined_rows = []\n",
    "    counts = {'accepted': 0, 'pending': 0, 'blocked': 0}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(f\"ðŸ”„ Processing: {filename}\")\n",
    "        rows, counts = process_csv_file(file_path, counts)\n",
    "        combined_rows.extend(rows)\n",
    "    \n",
    "        if all(counts[d] >= MAX_PER_CLASS for d in ['accepted', 'pending', 'blocked']):\n",
    "            print(\"âœ… All classes reached their limits. Stopping early.\")\n",
    "            break\n",
    "\n",
    "    final_output = pd.DataFrame(combined_rows)\n",
    "    final_output.to_csv(\"final1_csv.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"âœ… Saved final1_csv.csv with class caps applied.\")\n",
    "    generate_summary_report(final_output)\n",
    "\n",
    "file_clean_summary_for_folder(r\"U:\\N\\new_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecb9495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Text          Label  \\\n",
      "0            oop nws nws, may I ask for future preface of           Junk   \n",
      "1             yeah i had to use my own like what the heck         Vulgar   \n",
      "2                                              on you too  Nothing Wrong   \n",
      "3                                            First letter         Vulgar   \n",
      "4                                         THEY are stinky       Bullying   \n",
      "...                                                   ...            ...   \n",
      "3005110                                           trumpet       Politics   \n",
      "3005111                                 ur rose look slay       Fighting   \n",
      "3005112  NO OFFNESE BUT HE IS SO ANNOYING SOMETIMES HAHAH       Bullying   \n",
      "3005113                                           Trumpet       Politics   \n",
      "3005114                      we got richie rich over here       RealName   \n",
      "\n",
      "         Status  Decision  \n",
      "0             2  accepted  \n",
      "1             5   blocked  \n",
      "2             0  accepted  \n",
      "3             5   blocked  \n",
      "4             5   blocked  \n",
      "...         ...       ...  \n",
      "3005110       3   pending  \n",
      "3005111       3   pending  \n",
      "3005112       3   pending  \n",
      "3005113       3   pending  \n",
      "3005114       3   pending  \n",
      "\n",
      "[3005115 rows x 4 columns]\n",
      "3005116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = pd.read_csv('final1_csv.csv')\n",
    "print(res)\n",
    "with open('final1_csv.csv', 'r', encoding='utf-8') as f:\n",
    "    res = sum(1 for line in f)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b25d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Load final_output (skip if it's already loaded)\n",
    "# final_output = pd.read_csv(\"final_csv0.csv\")\n",
    "\n",
    "\n",
    "# # Filter only the rows with meaningful labels (skip 'Nothing Wrong' if not useful)\n",
    "# df_balanced_input = final_output[final_output['Label'] != 'Nothing Wrong'].copy()\n",
    "\n",
    "\n",
    "# # Step 1: Vectorize the text\n",
    "# vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# X = vectorizer.fit_transform(df_balanced_input['Text'])\n",
    "\n",
    "\n",
    "# # Step 2: Encode the Decision labels\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(df_balanced_input['Decision'])  # e.g., accepted -> 0, blocked -> 1, etc.\n",
    "\n",
    "\n",
    "# # Step 3: Apply SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# # Step 4: Map back to original labels\n",
    "# balanced_df = pd.DataFrame(X_resampled.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# balanced_df['Text'] = vectorizer.inverse_transform(X_resampled)\n",
    "# balanced_df['Text'] = [' '.join(text) for text in balanced_df['Text']]\n",
    "# balanced_df['Decision'] = le.inverse_transform(y_resampled)\n",
    "\n",
    "\n",
    "# # Optional: Merge original labels back (one way is to randomly assign corresponding labels per class)\n",
    "# # For this, we'll fetch one representative label per class\n",
    "# label_map = df_balanced_input.groupby('Decision')['Label'].apply(list).to_dict()\n",
    "\n",
    "\n",
    "# # Randomly assign original labels from each class\n",
    "# import random\n",
    "# balanced_df['Label'] = balanced_df['Decision'].apply(lambda d: random.choice(label_map[d]))\n",
    "# balanced_df['Status'] = balanced_df['Decision'].map({\n",
    "#     'accepted': 1,\n",
    "#     'pending': 4,\n",
    "#     'blocked': 6\n",
    "# })  # or keep it as placeholder\n",
    "\n",
    "\n",
    "# # Save to new CSV\n",
    "# balanced_df.to_csv(\"balanced_decision_csv0.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "# # Optional: Show class distribution\n",
    "# print(\"\\nðŸ“Š Balanced Class Distribution:\")\n",
    "# print(balanced_df['Decision'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c498ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import random\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# # Load and filter\n",
    "# final_output = pd.read_csv(\"final_csv0.csv\")\n",
    "# df_balanced_input = final_output[final_output['Label'] != 'Nothing Wrong'].copy()\n",
    "\n",
    "# # Vectorize\n",
    "# vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# X = vectorizer.fit_transform(df_balanced_input['Text'])\n",
    "\n",
    "# # Encode labels\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(df_balanced_input['Decision'])\n",
    "\n",
    "# # SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# # Map y back to text decisions\n",
    "# y_labels = le.inverse_transform(y_resampled)\n",
    "\n",
    "# # Group original rows (Text, Label, Status) per Decision\n",
    "# decision_to_rows = df_balanced_input.groupby('Decision')[['Text', 'Label', 'Status']].apply(lambda g: g.to_dict('records')).to_dict()\n",
    "\n",
    "# # Generate final balanced rows\n",
    "# balanced_rows = []\n",
    "# for decision in y_labels:\n",
    "#     row = random.choice(decision_to_rows[decision])  # sample actual row\n",
    "#     balanced_rows.append({\n",
    "#         'Text': row['Text'],\n",
    "#         'Label': row['Label'],\n",
    "#         'Status': row['Status'],\n",
    "#         'Decision': decision\n",
    "#     })\n",
    "\n",
    "# # Save final readable CSV\n",
    "# balanced_final_df = pd.DataFrame(balanced_rows)\n",
    "# balanced_final_df.to_csv(\"balanced_final_csv0.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(\"âœ… Saved as balanced_final_csv0.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee69230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the balanced data if not already in memory\n",
    "# # balanced_final_df = pd.read_csv(\"balanced_final_csv0.csv\")  # Uncomment if needed\n",
    "\n",
    "# summary_data = []\n",
    "\n",
    "# # ðŸ“Œ Overall decision summary\n",
    "# decision_counts = balanced_final_df['Decision'].value_counts().to_dict()\n",
    "# summary_data.append(['Summary'])\n",
    "# summary_data.append(['Overall accepted', decision_counts.get('accepted', 0)])\n",
    "# summary_data.append(['Overall pending', decision_counts.get('pending', 0)])\n",
    "# summary_data.append(['Overall blocked', decision_counts.get('blocked', 0)])\n",
    "# summary_data.append([])  # Blank row\n",
    "\n",
    "# # ðŸ“Œ Count of \"Nothing Wrong\" (just for completeness; should be 0)\n",
    "# nothing_wrong_count = balanced_final_df[balanced_final_df['Label'] == 'Nothing Wrong'].shape[0]\n",
    "# summary_data.append(['Nothing Wrong', nothing_wrong_count])\n",
    "# summary_data.append([])\n",
    "\n",
    "# # ðŸ“Œ Per-label summary\n",
    "# summary_data.append(['Per-label Summary', 'Accepted', 'Pending', 'Blocked'])\n",
    "\n",
    "# # Group and summarize\n",
    "# label_stats = (\n",
    "#     balanced_final_df[balanced_final_df['Label'] != 'Nothing Wrong']\n",
    "#     .groupby(['Label', 'Decision'])\n",
    "#     .size()\n",
    "#     .unstack(fill_value=0)\n",
    "# )\n",
    "\n",
    "# for label in label_stats.index:\n",
    "#     accepted = label_stats.loc[label].get('accepted', 0)\n",
    "#     pending = label_stats.loc[label].get('pending', 0)\n",
    "#     blocked = label_stats.loc[label].get('blocked', 0)\n",
    "#     summary_data.append([label, accepted, pending, blocked])\n",
    "\n",
    "# # Save summary to CSV\n",
    "# summary_df = pd.DataFrame(summary_data)\n",
    "# summary_df.to_csv(\"balanced_summary_report_csv0.csv\", index=False, header=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# # Print in console\n",
    "# print(\"\\nðŸ“Š Balanced Summary Report:\\n\")\n",
    "# for row in summary_data:\n",
    "#     print(', '.join(str(cell) for cell in row if cell != ''))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
